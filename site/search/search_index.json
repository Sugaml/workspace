{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Sugam Workspace \"Streamline Your Workflow with Sugam Workspace!\" Project Layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. prometheus.md logging.md ... # Other markdown pages, images and other files.","title":"Welcome to Sugam Workspace"},{"location":"#welcome-to-sugam-workspace","text":"","title":"Welcome to Sugam Workspace"},{"location":"#streamline-your-workflow-with-sugam-workspace","text":"","title":"\"Streamline Your Workflow with Sugam Workspace!\""},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. prometheus.md logging.md ... # Other markdown pages, images and other files.","title":"Project Layout"},{"location":"kubernetes/","text":"Kubernetes Troubleshooting Inroduction Kubernetes troubleshooting is the process of identifying, diagnosing, and resolving issues in kubernetes cluster, nodes, pods, or containers. This browser does not support PDFs. Please download the PDF to view it: Download PDF . Kubernetes Cluster Architecture Each Kubernetes cluster is composed of: Nodes Represent a physical or virtual machine with the container runtime to support one or more containers. Nodes in an operating cluster can be categorized into: * Master node Hosts the cluster\u2019s control plane and is responsible for scheduling workloads, scaling, and managing the cluster state. Each cluster must have at least one master node; however, a typical choice is to provision two or more master nodes for redundancy. Worker node Hosts workloads in containers and performs the duties assigned to it by the master node.\u200d Control plane Composed of a number of cluster components, it\u2019s responsible for controlling the cluster to achieve a desired state.\u200d Kube-API server The front-end server that manages all external communication with the cluster.\u200d Etcd The key value database that stores cluster state and data.\u200d Kube-scheduler Uses etcd event data to schedule workloads on worker nodes.\u200d Kube-controller manager Runs a set of controllers that govern the state of the cluster\u200d Kubelet An agent that runs on each worker node to communicate with the API server, it\u2019s responsible for the deployment of containerized workloads in pods.\u200d Kube-proxy Maintains network rules that allow communication between pods and services, both internal and external to the cluster. Get Started Install Kind curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64 chmod +x ./kind mv ./kind /usr/local/bin which kind kind version Install kubectl curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl chmod +x kubectl mv ./kubectl /usr/local/bin/kubectl kubectl version --client Create Kind Cluster kind create cluster Install Metrics Server ( kubectl top ) Issue #1 :: Kubernetes metrics-server Error \u2013 Readiness probe failed: HTTP probe failed with statuscode Solution: Download https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml Modify and add \"- --kubelet-insecure-tls\" in deployment.spec.template.spec.containers.args kubectl apply -f components.yaml kubectl top nodes kubectl top pod kube-proxy-5p7gr -n=kube-system Create Deployment Manifest apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-test name: nginx-test spec: replicas: 1 selector: matchLabels: app: nginx-test template: metadata: labels: app: nginx-test spec: containers: - image: nginx name: nginx-test ports: - containerPort: 80 name: http protocol: TCP Create Service Manifest apiVersion: v1 kind: Service metadata: name: nginx-test spec: ports: - port: 80 selector: app: nginx-test Install MetalLB kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.5/config/manifests/metallb-native.yaml View subnet-mask docker inspect <container_name> Create MeatlLB manifest --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: empty namespace: metallb-system --- apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: example namespace: metallb-system spec: addresses: - 172.19.254.200-172.19.254.250 #chage first 2 numbers as per subnet mask. Install Nginx-controller kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.1/deploy/static/provider/cloud/deploy.yaml To add hosts on etc/hosts sudo nano /etc/hosts Create Ingress Manifest apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: myhost spec: rules: - host: myhost.example.com http: paths: - backend: service: name: nginx-test # change as per service name port: number: 80 # change as per service port path: / pathType: ImplementationSpecific","title":"Kubernetes Troubleshooting"},{"location":"kubernetes/#kubernetes-troubleshooting","text":"","title":"Kubernetes Troubleshooting"},{"location":"kubernetes/#inroduction","text":"Kubernetes troubleshooting is the process of identifying, diagnosing, and resolving issues in kubernetes cluster, nodes, pods, or containers. This browser does not support PDFs. Please download the PDF to view it: Download PDF .","title":"Inroduction"},{"location":"kubernetes/#kubernetes-cluster-architecture","text":"Each Kubernetes cluster is composed of: Nodes Represent a physical or virtual machine with the container runtime to support one or more containers. Nodes in an operating cluster can be categorized into: * Master node Hosts the cluster\u2019s control plane and is responsible for scheduling workloads, scaling, and managing the cluster state. Each cluster must have at least one master node; however, a typical choice is to provision two or more master nodes for redundancy. Worker node Hosts workloads in containers and performs the duties assigned to it by the master node.\u200d Control plane Composed of a number of cluster components, it\u2019s responsible for controlling the cluster to achieve a desired state.\u200d Kube-API server The front-end server that manages all external communication with the cluster.\u200d Etcd The key value database that stores cluster state and data.\u200d Kube-scheduler Uses etcd event data to schedule workloads on worker nodes.\u200d Kube-controller manager Runs a set of controllers that govern the state of the cluster\u200d Kubelet An agent that runs on each worker node to communicate with the API server, it\u2019s responsible for the deployment of containerized workloads in pods.\u200d Kube-proxy Maintains network rules that allow communication between pods and services, both internal and external to the cluster.","title":"Kubernetes Cluster Architecture"},{"location":"kubernetes/#get-started","text":"","title":"Get Started"},{"location":"kubernetes/#install-kind","text":"curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64 chmod +x ./kind mv ./kind /usr/local/bin which kind kind version","title":"Install Kind"},{"location":"kubernetes/#install-kubectl","text":"curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl chmod +x kubectl mv ./kubectl /usr/local/bin/kubectl kubectl version --client","title":"Install kubectl"},{"location":"kubernetes/#create-kind-cluster","text":"kind create cluster","title":"Create Kind Cluster"},{"location":"kubernetes/#install-metrics-server-kubectl-top","text":"Issue #1 :: Kubernetes metrics-server Error \u2013 Readiness probe failed: HTTP probe failed with statuscode Solution: Download https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml Modify and add \"- --kubelet-insecure-tls\" in deployment.spec.template.spec.containers.args kubectl apply -f components.yaml kubectl top nodes kubectl top pod kube-proxy-5p7gr -n=kube-system","title":"Install Metrics Server (kubectl top)"},{"location":"kubernetes/#create-deployment-manifest","text":"apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-test name: nginx-test spec: replicas: 1 selector: matchLabels: app: nginx-test template: metadata: labels: app: nginx-test spec: containers: - image: nginx name: nginx-test ports: - containerPort: 80 name: http protocol: TCP","title":"Create Deployment Manifest"},{"location":"kubernetes/#create-service-manifest","text":"apiVersion: v1 kind: Service metadata: name: nginx-test spec: ports: - port: 80 selector: app: nginx-test","title":"Create Service Manifest"},{"location":"kubernetes/#install-metallb","text":"kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.5/config/manifests/metallb-native.yaml","title":"Install MetalLB"},{"location":"kubernetes/#view-subnet-mask","text":"docker inspect <container_name>","title":"View subnet-mask"},{"location":"kubernetes/#create-meatllb-manifest","text":"--- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: empty namespace: metallb-system --- apiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: example namespace: metallb-system spec: addresses: - 172.19.254.200-172.19.254.250 #chage first 2 numbers as per subnet mask.","title":"Create MeatlLB manifest"},{"location":"kubernetes/#install-nginx-controller","text":"kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.1/deploy/static/provider/cloud/deploy.yaml","title":"Install Nginx-controller"},{"location":"kubernetes/#to-add-hosts-on-etchosts","text":"sudo nano /etc/hosts","title":"To add hosts on etc/hosts"},{"location":"kubernetes/#create-ingress-manifest","text":"apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: kubernetes.io/ingress.class: nginx name: myhost spec: rules: - host: myhost.example.com http: paths: - backend: service: name: nginx-test # change as per service name port: number: 80 # change as per service port path: / pathType: ImplementationSpecific","title":"Create Ingress Manifest"},{"location":"logging/","text":"Loogging Using Helm Chart Add the Helm Repository helm repo add grafana https://grafana.github.io/helm-charts Add the Helm Repository helm install loki grafana/loki-stack -n monitoring Add the datasource to the grafana dashboard Go to the explore section and select loki as a datasource from drop-down list Use the log query to fetch the logs","title":"Loogging"},{"location":"logging/#loogging","text":"","title":"Loogging"},{"location":"logging/#using-helm-chart","text":"","title":"Using Helm Chart"},{"location":"logging/#add-the-helm-repository","text":"helm repo add grafana https://grafana.github.io/helm-charts","title":"Add the Helm Repository"},{"location":"logging/#add-the-helm-repository_1","text":"helm install loki grafana/loki-stack -n monitoring","title":"Add the Helm Repository"},{"location":"logging/#add-the-datasource-to-the-grafana-dashboard","text":"","title":"Add the datasource to the grafana dashboard"},{"location":"logging/#go-to-the-explore-section-and-select-loki-as-a-datasource-from-drop-down-list","text":"","title":"Go to the explore section and select loki as a datasource from drop-down list"},{"location":"logging/#use-the-log-query-to-fetch-the-logs","text":"","title":"Use the log query to fetch the logs"},{"location":"prometheus/","text":"Monitoring Add Helm Repository helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update Install Prometheus helm upgrade --install monitoring prometheus-community/prometheus --set persistence.enabled=true,persistence.size=8Gi --namespace monitoring Logging Add Helm Repository helm repo add grafana https://grafana.github.io/helm-charts Install Loki Stack helm install loki grafana/loki-stack -n monitoring Observablity Install Grafana Dashbaord helm install grafana grafana/grafana --namespace monitoring --set persistence.enabled=true,persistence.size=1Gi Alerting Add gChat Alert Repository helm repo add julb https://charts.julb.me Install gChat Alert helm install alert-manager julb/alertmanager-gchat-integration --namespace monitoring Step 2: Verify if all the pods are running. kubectl get pods -n monitoring Step 3: Verify service available. kubectl get svc -n monitoring Step 4: Update configmap of prometheus alert-manager with the webhook url of gchat. apiVersion: v1 data: alertmanager.yml: | global: {} receivers: webhook_configs: - url: 'http://<GCHAT_SERVICE-NAME>:<SERVICE_PORT>/alerts?room=<Google_Room_Name>' ``` References https://prometheus.io/docs/alerting/latest/configuration/#webhook_config https://stackoverflow.com/questions/66333868/send-notification-from-prometheus-alertmanager-to-google-chat-room/66337152#66337152 https://github.com/mr-karan/calert","title":"Monitoring"},{"location":"prometheus/#monitoring","text":"","title":"Monitoring"},{"location":"prometheus/#add-helm-repository","text":"helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update","title":"Add Helm Repository"},{"location":"prometheus/#install-prometheus","text":"helm upgrade --install monitoring prometheus-community/prometheus --set persistence.enabled=true,persistence.size=8Gi --namespace monitoring","title":"Install Prometheus"},{"location":"prometheus/#logging","text":"","title":"Logging"},{"location":"prometheus/#add-helm-repository_1","text":"helm repo add grafana https://grafana.github.io/helm-charts","title":"Add Helm Repository"},{"location":"prometheus/#install-loki-stack","text":"helm install loki grafana/loki-stack -n monitoring","title":"Install Loki Stack"},{"location":"prometheus/#observablity","text":"","title":"Observablity"},{"location":"prometheus/#install-grafana-dashbaord","text":"helm install grafana grafana/grafana --namespace monitoring --set persistence.enabled=true,persistence.size=1Gi","title":"Install Grafana Dashbaord"},{"location":"prometheus/#alerting","text":"","title":"Alerting"},{"location":"prometheus/#add-gchat-alert-repository","text":"helm repo add julb https://charts.julb.me","title":"Add gChat Alert Repository"},{"location":"prometheus/#install-gchat-alert","text":"helm install alert-manager julb/alertmanager-gchat-integration --namespace monitoring","title":"Install gChat Alert"},{"location":"prometheus/#step-2","text":"Verify if all the pods are running. kubectl get pods -n monitoring","title":"Step 2:"},{"location":"prometheus/#step-3","text":"Verify service available. kubectl get svc -n monitoring","title":"Step 3:"},{"location":"prometheus/#step-4","text":"Update configmap of prometheus alert-manager with the webhook url of gchat. apiVersion: v1 data: alertmanager.yml: | global: {} receivers: webhook_configs: - url: 'http://<GCHAT_SERVICE-NAME>:<SERVICE_PORT>/alerts?room=<Google_Room_Name>' ```","title":"Step 4:"},{"location":"prometheus/#references","text":"https://prometheus.io/docs/alerting/latest/configuration/#webhook_config https://stackoverflow.com/questions/66333868/send-notification-from-prometheus-alertmanager-to-google-chat-room/66337152#66337152 https://github.com/mr-karan/calert","title":"References"}]}